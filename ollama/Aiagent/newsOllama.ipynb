{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c0b0dcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a8014773",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = DuckDuckGoSearchRun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "642f9b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(\n",
    "    model='llama3.2:1b',\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "912864e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def summarize(news: str)->str:\n",
    "    \"\"\"\n",
    "    this function Summarize this entire news in 1 line\n",
    "    \"\"\"\n",
    "    return llm.invoke(f'Summarize this entire news in 1 line {news}').content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "59e3912b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def sentiment_score(text: str)->str:\n",
    "    \"\"\"\n",
    "    this function tells the sentiment is it a postive or negative\n",
    "    \"\"\"\n",
    "    return llm.invoke(f'tells the emotions postive or negative {text}').content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f42e9989",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_19148\\2105107940.py:1: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  agent = create_react_agent(\n"
     ]
    }
   ],
   "source": [
    "agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=[search_results,summarize,sentiment_score]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e77cc75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.invoke({\n",
    "    'messages':[\n",
    "        (\"user\",\"Get latest coronavirus news. Then: 1. Give heading 2. Give 1-line summary 3. Give sentiment (Positive / Negative)\")\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cc323a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='Get latest coronavirus news. Then: 1. Give heading 2. Give 1-line summary 3. Give sentiment (Positive / Negative)', additional_kwargs={}, response_metadata={}, id='8b168027-4b45-4351-b32f-951f7b500e41'), AIMessage(content='{\\n  \"name\": \"{function <nil> {duckduckgo_search A wrapper around DuckDuckGo Search. Useful for when you need to answer questions about current events. Input should be a search query. {object <nil> <nil> [query] {\"query\":{\"type\":\"string\",\"description\":\"search query to look up\"}}}}\",\\n  \"parameters\": {\\n    \"duckduckgo_search\": \"{\\\\\"query\\\\\":{\\\\\"type\\\\\":\\\\\"string\\\\\",\\\\\"description\\\\\":\\\\\"search query to look up\\\\\"}}\"\\n  }\\n}\\n\\n{\\n  \"name\": \"{function <nil> {summarize this function Summarize this entire news in 1 line {object <nil> <nil> [news] {\"news\":{\"type\":\"string\"}}}}\",\\n  \"parameters\": {\\n    \"news\": \"{\\\\\"news\\\\\":{\\\\\"type\\\\\":\\\\\"string\\\\\"}}\"\\n  }\\n}\\n\\n{\\n  \"name\": \"{function <nil> {sentiment_score this function tells the sentiment is it a postive or negative {object <nil> <nil> [text] {\"text\":{\"type\":\"string\"}}}}\",\\n  \"parameters\": {\\n    \"text\": \"{\\\\\"text\\\\\":{\\\\\"type\\\\\":\\\\\"string\\\\\"}}\"\\n  }\\n}', additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2026-02-25T10:17:44.8998153Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2516516700, 'load_duration': 176967300, 'prompt_eval_count': 286, 'prompt_eval_duration': 225026300, 'eval_count': 235, 'eval_duration': 1640357700, 'logprobs': None, 'model_name': 'llama3.2:1b', 'model_provider': 'ollama'}, id='lc_run--019c944d-f2ee-7d53-bd43-38eac14d2f6e-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 286, 'output_tokens': 235, 'total_tokens': 521})]}\n"
     ]
    }
   ],
   "source": [
    "print(response['messages'][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
